{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_community.vectorstores import chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/1-build-basic-chatbot/#2-create-a-stategraph', 'title': 'Build a basic chatbot', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBuild a basic chatbot\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Build a basic chatbot\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install packages\\n    \\n\\n\\n\\n\\n\\n      2. Create a StateGraph\\n    \\n\\n\\n\\n\\n\\n      3. Add a node\\n    \\n\\n\\n\\n\\n\\n      4. Add an entry point\\n    \\n\\n\\n\\n\\n\\n      5. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      6. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      7. Run the chatbot\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install packages\\n    \\n\\n\\n\\n\\n\\n      2. Create a StateGraph\\n    \\n\\n\\n\\n\\n\\n      3. Add a node\\n    \\n\\n\\n\\n\\n\\n      4. Add an entry point\\n    \\n\\n\\n\\n\\n\\n      5. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      6. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      7. Run the chatbot\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBuild a basic chatbot¶\\nIn this tutorial, you will build a basic chatbot. This chatbot is the basis for the following series of tutorials where you will progressively add more sophisticated capabilities, and be introduced to key LangGraph concepts along the way. Let‚Äôs dive in! \\uf8ffüåü\\nPrerequisites¶\\nBefore you start this tutorial, ensure you have access to a LLM that supports\\ntool-calling features, such as OpenAI,\\nAnthropic, or\\nGoogle Gemini.\\n1. Install packages¶\\nInstall the required packages:\\npip install -U langgraph langsmith\\n\\n\\nTip\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph. For more information on how to get started, see LangSmith docs. \\n\\n2. Create a StateGraph¶\\nNow you can create a basic chatbot using LangGraph. This chatbot will respond directly to user messages.\\nStart by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We\\'ll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions.\\nAPI Reference: StateGraph | START | add_messages\\nfrom typing import Annotated\\n\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START\\nfrom langgraph.graph.message import add_messages\\n\\n\\nclass State(TypedDict):\\n    # Messages have the type \"list\". The `add_messages` function\\n    # in the annotation defines how this state key should be updated\\n    # (in this case, it appends messages to the list, rather than overwriting them)\\n    messages: Annotated[list, add_messages]\\n\\n\\ngraph_builder = StateGraph(State)\\n\\nOur graph can now handle two key tasks:\\n\\nEach node can receive the current State as input and output an update to the state.\\nUpdates to messages will be appended to the existing list rather than overwriting it, thanks to the prebuilt add_messages function used with the Annotated syntax.\\n\\n\\n\\nConcept\\nWhen defining a graph, the first step is to define its State. The State includes the graph\\'s schema and reducer functions that handle state updates. In our example, State is a TypedDict with one key: messages. The add_messages reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values. To learn more about state, reducers, and related concepts, see LangGraph reference docs.\\n\\n3. Add a node¶\\nNext, add a \"chatbot\" node. Nodes represent units of work and are typically regular Python functions.\\nLet\\'s first select a chat model:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nWe can now incorporate the chat model into a simple node:\\ndef chatbot(state: State):\\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n\\n\\n# The first argument is the unique node name\\n# The second argument is the function or object that will be called whenever\\n# the node is used.\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\nNotice how the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\\nThe add_messages function in our State will append the LLM\\'s response messages to whatever messages are already in the state.\\n4. Add an entry point¶\\nAdd an entry point to tell the graph where to start its work each time it is run:\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\n5. Compile the graph¶\\nBefore running the graph, we\\'ll need to compile it. We can do so by calling compile()\\non the graph builder. This creates a CompiledGraph we can invoke on our state.\\ngraph = graph_builder.compile()\\n\\n6. Visualize the graph (optional)¶\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n7. Run the chatbot¶\\nNow run the chatbot! \\n\\nTip\\nYou can exit the chat loop at any time by typing quit, exit, or q.\\n\\ndef stream_graph_updates(user_input: str):\\n    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n        for value in event.values():\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\n\\n\\nwhile True:\\n    try:\\n        user_input = input(\"User: \")\\n        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n            print(\"Goodbye!\")\\n            break\\n        stream_graph_updates(user_input)\\n    except:\\n        # fallback if input() is not available\\n        user_input = \"What do you know about LangGraph?\"\\n        print(\"User: \" + user_input)\\n        stream_graph_updates(user_input)\\n        break\\n\\nAssistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It\\'s particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.\\nGoodbye!\\n\\nCongratulations! You\\'ve built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a LangSmith Trace for the call above.\\nBelow is the full code for this tutorial:\\nAPI Reference: init_chat_model | StateGraph | START | add_messages\\nfrom typing import Annotated\\n\\nfrom langchain.chat_models import init_chat_model\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START\\nfrom langgraph.graph.message import add_messages\\n\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\n\\ngraph_builder = StateGraph(State)\\n\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n\\n\\n# The first argument is the unique node name\\n# The second argument is the function or object that will be called whenever\\n# the node is used.\\ngraph_builder.add_node(\"chatbot\", chatbot)\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\nNext steps¶\\nYou may have noticed that the bot\\'s knowledge is limited to what\\'s in its training data. In the next part, we\\'ll add a web search tool to expand the bot\\'s knowledge and make it more capable.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add tools\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ‚ù§Ô∏è\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/#1-install-the-search-engine', 'title': 'Add tools', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd tools\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Add tools\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install the search engine\\n    \\n\\n\\n\\n\\n\\n      2. Configure your environment\\n    \\n\\n\\n\\n\\n\\n      3. Define the tool\\n    \\n\\n\\n\\n\\n\\n      4. Define the graph\\n    \\n\\n\\n\\n\\n\\n      5. Create a function to run the tools\\n    \\n\\n\\n\\n\\n\\n      6. Define the conditional_edges\\n    \\n\\n\\n\\n\\n\\n      7. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      8. Ask the bot questions\\n    \\n\\n\\n\\n\\n\\n      9. Use prebuilts\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install the search engine\\n    \\n\\n\\n\\n\\n\\n      2. Configure your environment\\n    \\n\\n\\n\\n\\n\\n      3. Define the tool\\n    \\n\\n\\n\\n\\n\\n      4. Define the graph\\n    \\n\\n\\n\\n\\n\\n      5. Create a function to run the tools\\n    \\n\\n\\n\\n\\n\\n      6. Define the conditional_edges\\n    \\n\\n\\n\\n\\n\\n      7. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      8. Ask the bot questions\\n    \\n\\n\\n\\n\\n\\n      9. Use prebuilts\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd tools¶\\nTo handle queries you chatbot can\\'t answer \"from memory\", integrate a web search tool. The chatbot can use this tool to find relevant information and provide better responses.\\n\\nNote\\nThis tutorial builds on Build a basic chatbot.\\n\\nPrerequisites¶\\nBefore you start this tutorial, ensure you have the following:\\n\\nAn API key for the Tavily Search Engine.\\n\\n1. Install the search engine¶\\nInstall the requirements to use the Tavily Search Engine:\\npip install -U langchain-tavily\\n\\n2. Configure your environment¶\\nConfigure your environment with your search engine API key:\\n_set_env(\"TAVILY_API_KEY\")\\n\\nTAVILY_API_KEY:  ········\\n\\n3. Define the tool¶\\nDefine the web search tool:\\nAPI Reference: TavilySearch\\nfrom langchain_tavily import TavilySearch\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\ntool.invoke(\"What\\'s a \\'node\\' in LangGraph?\")\\n\\nThe results are page summaries our chat bot can use to answer questions:\\n{\\'query\\': \"What\\'s a \\'node\\' in LangGraph?\",\\n\\'follow_up_questions\\': None,\\n\\'answer\\': None,\\n\\'images\\': [],\\n\\'results\\': [{\\'title\\': \"Introduction to LangGraph: A Beginner\\'s Guide - Medium\",\\n\\'url\\': \\'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\\',\\n\\'content\\': \\'Stateful Graph: LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. We define nodes for classifying the input, handling greetings, and handling search queries. def classify_input_node(state): LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph.\\',\\n\\'score\\': 0.7065353,\\n\\'raw_content\\': None},\\n{\\'title\\': \\'LangGraph Tutorial: What Is LangGraph and How to Use It?\\',\\n\\'url\\': \\'https://www.datacamp.com/tutorial/langgraph-tutorial\\',\\n\\'content\\': \\'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\\',\\n\\'score\\': 0.5008063,\\n\\'raw_content\\': None}],\\n\\'response_time\\': 1.38}\\n\\n4. Define the graph¶\\nFor the StateGraph you created in the first tutorial, add bind_tools on the LLM. This lets the LLM know the correct JSON format to use if it wants to use the search engine.\\nLet\\'s first select our LLM:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nWe can now incorporate it into a StateGraph:\\nfrom typing import Annotated\\n\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n# Modification: tell the LLM which tools it can call\\n# highlight-next-line\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\n5. Create a function to run the tools¶\\nNow, create a function to run the tools if they are called. Do this by adding the tools to a new node calledBasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM\\'s tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\\nAPI Reference: ToolMessage\\nimport json\\n\\nfrom langchain_core.messages import ToolMessage\\n\\n\\nclass BasicToolNode:\\n    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\\n\\n    def __init__(self, tools: list) -> None:\\n        self.tools_by_name = {tool.name: tool for tool in tools}\\n\\n    def __call__(self, inputs: dict):\\n        if messages := inputs.get(\"messages\", []):\\n            message = messages[-1]\\n        else:\\n            raise ValueError(\"No message found in input\")\\n        outputs = []\\n        for tool_call in message.tool_calls:\\n            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\\n                tool_call[\"args\"]\\n            )\\n            outputs.append(\\n                ToolMessage(\\n                    content=json.dumps(tool_result),\\n                    name=tool_call[\"name\"],\\n                    tool_call_id=tool_call[\"id\"],\\n                )\\n            )\\n        return {\"messages\": outputs}\\n\\n\\ntool_node = BasicToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\n\\nNote\\nIf you do not want to build this yourself in the future, you can use LangGraph\\'s prebuilt ToolNode.\\n\\n6. Define the conditional_edges¶\\nWith the tool node added, now you can define the conditional_edges. \\nEdges route the control flow from one node to the next. Conditional edges start from a single node and usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\\nNext, define a router function called route_tools that checks for tool_calls in the chatbot\\'s output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next. \\nThe condition will route to tools if tool calls are present and END if not. Because the condition can return END, you do not need to explicitly set a finish_point this time.\\ndef route_tools(\\n    state: State,\\n):\\n    \"\"\"\\n    Use in the conditional_edge to route to the ToolNode if the last message\\n    has tool calls. Otherwise, route to the end.\\n    \"\"\"\\n    if isinstance(state, list):\\n        ai_message = state[-1]\\n    elif messages := state.get(\"messages\", []):\\n        ai_message = messages[-1]\\n    else:\\n        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\\n    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\\n        return \"tools\"\\n    return END\\n\\n\\n# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\\n# it is fine directly responding. This conditional routing defines the main agent loop.\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    route_tools,\\n    # The following dictionary lets you tell the graph to interpret the condition\\'s outputs as a specific node\\n    # It defaults to the identity function, but if you\\n    # want to use a node named something else apart from \"tools\",\\n    # You can update the value of the dictionary to something else\\n    # e.g., \"tools\": \"my_tools\"\\n    {\"tools\": \"tools\", END: END},\\n)\\n# Any time a tool is called, we return to the chatbot to decide the next step\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\n\\nNote\\nYou can replace this with the prebuilt tools_condition to be more concise. \\n\\n7. Visualize the graph (optional)¶\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n8. Ask the bot questions¶\\nNow you can ask the chatbot questions outside its training data:\\ndef stream_graph_updates(user_input: str):\\n    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n        for value in event.values():\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\n\\nwhile True:\\n    try:\\n        user_input = input(\"User: \")\\n        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n            print(\"Goodbye!\")\\n            break\\n\\n        stream_graph_updates(user_input)\\n    except:\\n        # fallback if input() is not available\\n        user_input = \"What do you know about LangGraph?\"\\n        print(\"User: \" + user_input)\\n        stream_graph_updates(user_input)\\n        break\\n\\nAssistant: [{\\'text\\': \"To provide you with accurate and up-to-date information about LangGraph, I\\'ll need to search for the latest details. Let me do that for you.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01Q588CszHaSvvP2MxRq9zRD\\', \\'input\\': {\\'query\\': \\'LangGraph AI tool information\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\nAssistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\\\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\\nAssistant: Based on the search results, I can provide you with information about LangGraph:\\n\\n1. Purpose:\\n   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\n\\n2. Developer:\\n   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n\\n3. Key Features:\\n   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\\n   - Controllability: It offers enhanced control over the application flow.\\n   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\\n\\n4. Use Cases:\\n   LangGraph can be used for various applications, including:\\n   - Conversational agents\\n   - Complex task automation\\n   - Custom LLM-backed experiences\\n\\n5. Integration:\\n   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\\n\\n6. Significance:\\n...\\n   LangGraph is noted to offer unique benefits compared to other LLM frameworks, particularly in its ability to handle cycles, provide controllability, and maintain persistence.\\n\\nLangGraph appears to be a significant tool in the evolving landscape of LLM-based application development, offering developers new ways to create more complex, stateful, and interactive AI systems.\\nGoodbye!\\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\\n\\n9. Use prebuilts¶\\nFor ease of use, adjust your code to replace the following with LangGraph prebuilt components. These have built in functionality like parallel API execution.\\n\\nBasicToolNode is replaced with the prebuilt ToolNode\\nroute_tools is replaced with the prebuilt tools_condition\\n\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.messages import BaseMessage\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\n# Any time a tool is called, we return to the chatbot to decide the next step\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\nCongratulations! You\\'ve created a conversational agent in LangGraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this LangSmith trace.\\nNext steps¶\\nThe chatbot cannot remember past interactions on its own, which limits its ability to have coherent, multi-turn conversations. In the next part, you will add memory to address this.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Build a basic chatbot\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add memory\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/3-add-memory/', 'title': 'Add memory', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd memory\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Add memory\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Create a MemorySaver checkpointer\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Interact with your chatbot\\n    \\n\\n\\n\\n\\n\\n      4. Ask a follow up question\\n    \\n\\n\\n\\n\\n\\n      5. Inspect the state\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Create a MemorySaver checkpointer\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Interact with your chatbot\\n    \\n\\n\\n\\n\\n\\n      4. Ask a follow up question\\n    \\n\\n\\n\\n\\n\\n      5. Inspect the state\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd memory¶\\nThe chatbot can now use tools to answer user questions, but it does not remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\\nLangGraph solves this problem through persistent checkpointing. If you provide a checkpointer when compiling the graph and a thread_id when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same thread_id, the graph loads its saved state, allowing the chatbot to pick up where it left off. \\nWe will see later that checkpointing is much more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But first, let\\'s add checkpointing to enable multi-turn conversations.\\n\\nNote\\nThis tutorial builds on Add tools.\\n\\n1. Create a MemorySaver checkpointer¶\\nCreate a MemorySaver checkpointer:\\nfrom langgraph.checkpoint.memory import MemorySaver\\n\\nmemory = MemorySaver()\\n\\nThis is in-memory checkpointer, which is convenient for the tutorial. However, in a production application, you would likely change this to use SqliteSaver or PostgresSaver and connect a database.\\n2. Compile the graph¶\\nCompile the graph with the provided checkpointer, which will checkpoint the State as the graph works through each node:\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n3. Interact with your chatbot¶\\nNow you can interact with your bot!\\n\\n\\nPick a thread to use as the key for this conversation.\\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\\n\\n\\n\\nCall your chatbot:\\nuser_input = \"Hi there! My name is Will.\"\\n\\n# The config is the **second positional argument** to stream() or invoke()!\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    config,\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nHi there! My name is Will.\\n================================== Ai Message ==================================\\n\\nHello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\\n\\n\\nNote\\nThe config was provided as the second positional argument when calling our graph. It importantly is not nested within the graph inputs ({\\'messages\\': []}).\\n\\n\\n\\n4. Ask a follow up question¶\\nAsk a follow up question:\\nuser_input = \"Remember my name?\"\\n\\n# The config is the **second positional argument** to stream() or invoke()!\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    config,\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nRemember my name?\\n================================== Ai Message ==================================\\n\\nOf course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\\n\\nNotice that we aren\\'t using an external list for memory: it\\'s all handled by the checkpointer! You can inspect the full execution in this LangSmith trace to see what\\'s going on.\\nDon\\'t believe me? Try this using a different config.\\n# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    {\"configurable\": {\"thread_id\": \"2\"}},\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nRemember my name?\\n================================== Ai Message ==================================\\n\\nI apologize, but I don\\'t have any previous context or memory of your name. As an AI assistant, I don\\'t retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?\\n\\nNotice that the only change we\\'ve made is to modify the thread_id in the config. See this call\\'s LangSmith trace for comparison.\\n5. Inspect the state¶\\nBy now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph\\'s state for a given config at any time, call get_state(config).\\nsnapshot = graph.get_state(config)\\nsnapshot\\n\\nStateSnapshot(values={\\'messages\\': [HumanMessage(content=\\'Hi there! My name is Will.\\', additional_kwargs={}, response_metadata={}, id=\\'8c1ca919-c553-4ebf-95d4-b59a2d61e078\\'), AIMessage(content=\"Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01WTQebPhNwmMrmmWojJ9KXJ\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 405, \\'output_tokens\\': 32}}, id=\\'run-58587b77-8c82-41e6-8a90-d62c444a261d-0\\', usage_metadata={\\'input_tokens\\': 405, \\'output_tokens\\': 32, \\'total_tokens\\': 437}), HumanMessage(content=\\'Remember my name?\\', additional_kwargs={}, response_metadata={}, id=\\'daba7df6-ad75-4d6b-8057-745881cea1ca\\'), AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}, next=(), config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-93e0-6acc-8004-f2ac846575d2\\'}}, metadata={\\'source\\': \\'loop\\', \\'writes\\': {\\'chatbot\\': {\\'messages\\': [AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}}, \\'step\\': 4, \\'parents\\': {}}, created_at=\\'2024-09-27T19:30:10.820758+00:00\\', parent_config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-859f-6206-8003-e1bd3c264b8f\\'}}, tasks=())\\n\\nsnapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)\\n\\nThe snapshot above contains the current state values, corresponding config, and the next node to process. In our case, the graph has reached an END state, so next is empty.\\nCongratulations! Your chatbot can now maintain conversation state across sessions thanks to LangGraph\\'s checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph\\'s checkpointing even handles arbitrarily complex graph states, which is much more expressive and powerful than simple chat memory.\\nCheck out the code snippet below to review the graph from this tutorial:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nAPI Reference: init_chat_model | TavilySearch | BaseMessage | MemorySaver | StateGraph | add_messages | ToolNode | tools_condition\\nfrom typing import Annotated\\n\\nfrom langchain.chat_models import init_chat_model\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.messages import BaseMessage\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.set_entry_point(\"chatbot\")\\nmemory = MemorySaver()\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\nNext steps¶\\nIn the next tutorial, you will add human-in-the-loop to the chatbot to handle situations where it may need guidance or verification before proceeding.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Add tools\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add human-in-the-loop\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n')],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/', 'title': 'Add human-in-the-loop', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd human-in-the-loop\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Add human-in-the-loop\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Add the human_assistance tool\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      4. Prompt the chatbot\\n    \\n\\n\\n\\n\\n\\n      5. Resume execution\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Add the human_assistance tool\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      4. Prompt the chatbot\\n    \\n\\n\\n\\n\\n\\n      5. Resume execution\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd human-in-the-loop controls¶\\nAgents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\\nLangGraph\\'s persistence layer supports human-in-the-loop workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the interrupt function. Calling interrupt inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a Command. interrupt is ergonomically similar to Python\\'s built-in input(), with some caveats.\\n\\nNote\\nThis tutorial builds on Add memory.\\n\\n1. Add the human_assistance tool¶\\nStarting with the existing code from the Add memory to the chatbot tutorial, add the human_assistance tool to the chatbot. This tool uses interrupt to receive information from a human.\\nLet\\'s first select a chat model:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nWe can now incorporate it into our StateGraph with an additional tool:\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.tools import tool\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nfrom langgraph.types import Command, interrupt\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool, human_assistance]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    message = llm_with_tools.invoke(state[\"messages\"])\\n    # Because we will be interrupting during tool execution,\\n    # we disable parallel tool calling to avoid repeating any\\n    # tool invocations when we resume.\\n    assert len(message.tool_calls) <= 1\\n    return {\"messages\": [message]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=tools)\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\n\\nTip\\nFor more information and examples of human-in-the-loop workflows, see Human-in-the-loop. This includes how to review and edit tool calls before they are executed.\\n\\n2. Compile the graph¶\\nWe compile the graph with a checkpointer, as before:\\nmemory = MemorySaver()\\n\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\n3. Visualize the graph (optional)¶\\nVisualizing the graph, you get the same layout as before – just with the added tool!\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n4. Prompt the chatbot¶\\nNow, prompt the chatbot with a question that will engage the new human_assistance tool:\\nuser_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\\n\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    config,\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    if \"messages\" in event:\\n        event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nI need some expert guidance for building an AI agent. Could you request assistance for me?\\n================================== Ai Message ==================================\\n\\n[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\nTool Calls:\\n  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n  Args:\\n    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n\\nThe chatbot generated a tool call, but then execution has been interrupted. If you inspect the graph state, you see that it stopped at the tools node:\\nsnapshot = graph.get_state(config)\\nsnapshot.next\\n\\n(\\'tools\\',)\\n\\n\\nInfo\\nTake a closer look at the human_assistance tool:\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\nSimilar to Python\\'s built-in input() function, calling interrupt inside the tool will pause execution. Progress is persisted based on the checkpointer; so if it is persisting with Postgres, it can resume at any time as long as the database is alive. In this example, it is persisting with the in-memory checkpointer and can resume any time if the Python kernel is running.\\n\\n5. Resume execution¶\\nTo resume execution, pass a Command object containing data expected by the tool. The format of this data can be customized based on needs. For this example, use a dict with a key \"data\":\\nhuman_response = (\\n    \"We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent.\"\\n    \" It\\'s much more reliable and extensible than simple autonomous agents.\"\\n)\\n\\nhuman_command = Command(resume={\"data\": human_response})\\n\\nevents = graph.stream(human_command, config, stream_mode=\"values\")\\nfor event in events:\\n    if \"messages\" in event:\\n        event[\"messages\"][-1].pretty_print()\\n\\n================================== Ai Message ==================================\\n\\n[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\nTool Calls:\\n  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n  Args:\\n    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n================================= Tool Message =================================\\nName: human_assistance\\n\\nWe, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent. It\\'s much more reliable and extensible than simple autonomous agents.\\n================================== Ai Message ==================================\\n\\nThank you for your patience. I\\'ve received some expert advice regarding your request for guidance on building an AI agent. Here\\'s what the experts have suggested:\\n\\nThe experts recommend that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\\n\\nLangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n\\n1. Reliability: The experts emphasize that LangGraph is more reliable than simpler autonomous agent approaches. This could mean it has better stability, error handling, or consistent performance.\\n\\n2. Extensibility: LangGraph is described as more extensible, which suggests that it probably offers a flexible architecture that allows you to easily add new features or modify existing ones as your agent\\'s requirements evolve.\\n\\n3. Advanced capabilities: Given that it\\'s recommended over \"simple autonomous agents,\" LangGraph likely provides more sophisticated tools and techniques for building complex AI agents.\\n...\\n2. Look for tutorials or guides specifically focused on building AI agents with LangGraph.\\n3. Check if there are any community forums or discussion groups where you can ask questions and get support from other developers using LangGraph.\\n\\nIf you\\'d like more specific information about LangGraph or have any questions about this recommendation, please feel free to ask, and I can request further assistance from the experts.\\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\\n\\nThe input has been received and processed as a tool message. Review this call\\'s LangSmith trace to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\\nCongratulations! You\\'ve used an interrupt to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since you have already added a checkpointer, as long as the underlying persistence layer is running, the graph can be paused indefinitely and resumed at any time as if nothing had happened.\\nCheck out the code snippet below to review the graph from this tutorial:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\nAPI Reference: TavilySearch | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.tools import tool\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\nfrom langgraph.types import Command, interrupt\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool, human_assistance]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    message = llm_with_tools.invoke(state[\"messages\"])\\n    assert(len(message.tool_calls) <= 1)\\n    return {\"messages\": [message]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=tools)\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\nmemory = MemorySaver()\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\nNext steps¶\\nSo far, the tutorial examples have relied on a simple state with one entry: a list of messages. You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Add memory\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Customize state\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n')]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/1-build-basic-chatbot/#2-create-a-stategraph\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/#1-install-the-search-engine\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/3-add-memory/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/\"\n",
    "]\n",
    "\n",
    "documents = [WebBaseLoader(url).load() for url in urls]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [items for sublist in documents for items in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/1-build-basic-chatbot/#2-create-a-stategraph', 'title': 'Build a basic chatbot', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBuild a basic chatbot\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Build a basic chatbot\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install packages\\n    \\n\\n\\n\\n\\n\\n      2. Create a StateGraph\\n    \\n\\n\\n\\n\\n\\n      3. Add a node\\n    \\n\\n\\n\\n\\n\\n      4. Add an entry point\\n    \\n\\n\\n\\n\\n\\n      5. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      6. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      7. Run the chatbot\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install packages\\n    \\n\\n\\n\\n\\n\\n      2. Create a StateGraph\\n    \\n\\n\\n\\n\\n\\n      3. Add a node\\n    \\n\\n\\n\\n\\n\\n      4. Add an entry point\\n    \\n\\n\\n\\n\\n\\n      5. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      6. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      7. Run the chatbot\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBuild a basic chatbot¶\\nIn this tutorial, you will build a basic chatbot. This chatbot is the basis for the following series of tutorials where you will progressively add more sophisticated capabilities, and be introduced to key LangGraph concepts along the way. Let‚Äôs dive in! \\uf8ffüåü\\nPrerequisites¶\\nBefore you start this tutorial, ensure you have access to a LLM that supports\\ntool-calling features, such as OpenAI,\\nAnthropic, or\\nGoogle Gemini.\\n1. Install packages¶\\nInstall the required packages:\\npip install -U langgraph langsmith\\n\\n\\nTip\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph. For more information on how to get started, see LangSmith docs. \\n\\n2. Create a StateGraph¶\\nNow you can create a basic chatbot using LangGraph. This chatbot will respond directly to user messages.\\nStart by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We\\'ll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions.\\nAPI Reference: StateGraph | START | add_messages\\nfrom typing import Annotated\\n\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START\\nfrom langgraph.graph.message import add_messages\\n\\n\\nclass State(TypedDict):\\n    # Messages have the type \"list\". The `add_messages` function\\n    # in the annotation defines how this state key should be updated\\n    # (in this case, it appends messages to the list, rather than overwriting them)\\n    messages: Annotated[list, add_messages]\\n\\n\\ngraph_builder = StateGraph(State)\\n\\nOur graph can now handle two key tasks:\\n\\nEach node can receive the current State as input and output an update to the state.\\nUpdates to messages will be appended to the existing list rather than overwriting it, thanks to the prebuilt add_messages function used with the Annotated syntax.\\n\\n\\n\\nConcept\\nWhen defining a graph, the first step is to define its State. The State includes the graph\\'s schema and reducer functions that handle state updates. In our example, State is a TypedDict with one key: messages. The add_messages reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values. To learn more about state, reducers, and related concepts, see LangGraph reference docs.\\n\\n3. Add a node¶\\nNext, add a \"chatbot\" node. Nodes represent units of work and are typically regular Python functions.\\nLet\\'s first select a chat model:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nWe can now incorporate the chat model into a simple node:\\ndef chatbot(state: State):\\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n\\n\\n# The first argument is the unique node name\\n# The second argument is the function or object that will be called whenever\\n# the node is used.\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\nNotice how the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\\nThe add_messages function in our State will append the LLM\\'s response messages to whatever messages are already in the state.\\n4. Add an entry point¶\\nAdd an entry point to tell the graph where to start its work each time it is run:\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\n5. Compile the graph¶\\nBefore running the graph, we\\'ll need to compile it. We can do so by calling compile()\\non the graph builder. This creates a CompiledGraph we can invoke on our state.\\ngraph = graph_builder.compile()\\n\\n6. Visualize the graph (optional)¶\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n7. Run the chatbot¶\\nNow run the chatbot! \\n\\nTip\\nYou can exit the chat loop at any time by typing quit, exit, or q.\\n\\ndef stream_graph_updates(user_input: str):\\n    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n        for value in event.values():\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\n\\n\\nwhile True:\\n    try:\\n        user_input = input(\"User: \")\\n        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n            print(\"Goodbye!\")\\n            break\\n        stream_graph_updates(user_input)\\n    except:\\n        # fallback if input() is not available\\n        user_input = \"What do you know about LangGraph?\"\\n        print(\"User: \" + user_input)\\n        stream_graph_updates(user_input)\\n        break\\n\\nAssistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It\\'s particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.\\nGoodbye!\\n\\nCongratulations! You\\'ve built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a LangSmith Trace for the call above.\\nBelow is the full code for this tutorial:\\nAPI Reference: init_chat_model | StateGraph | START | add_messages\\nfrom typing import Annotated\\n\\nfrom langchain.chat_models import init_chat_model\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START\\nfrom langgraph.graph.message import add_messages\\n\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\n\\ngraph_builder = StateGraph(State)\\n\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n\\n\\n# The first argument is the unique node name\\n# The second argument is the function or object that will be called whenever\\n# the node is used.\\ngraph_builder.add_node(\"chatbot\", chatbot)\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\nNext steps¶\\nYou may have noticed that the bot\\'s knowledge is limited to what\\'s in its training data. In the next part, we\\'ll add a web search tool to expand the bot\\'s knowledge and make it more capable.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add tools\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ‚ù§Ô∏è\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/#1-install-the-search-engine', 'title': 'Add tools', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd tools\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Add tools\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install the search engine\\n    \\n\\n\\n\\n\\n\\n      2. Configure your environment\\n    \\n\\n\\n\\n\\n\\n      3. Define the tool\\n    \\n\\n\\n\\n\\n\\n      4. Define the graph\\n    \\n\\n\\n\\n\\n\\n      5. Create a function to run the tools\\n    \\n\\n\\n\\n\\n\\n      6. Define the conditional_edges\\n    \\n\\n\\n\\n\\n\\n      7. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      8. Ask the bot questions\\n    \\n\\n\\n\\n\\n\\n      9. Use prebuilts\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Prerequisites\\n    \\n\\n\\n\\n\\n\\n      1. Install the search engine\\n    \\n\\n\\n\\n\\n\\n      2. Configure your environment\\n    \\n\\n\\n\\n\\n\\n      3. Define the tool\\n    \\n\\n\\n\\n\\n\\n      4. Define the graph\\n    \\n\\n\\n\\n\\n\\n      5. Create a function to run the tools\\n    \\n\\n\\n\\n\\n\\n      6. Define the conditional_edges\\n    \\n\\n\\n\\n\\n\\n      7. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      8. Ask the bot questions\\n    \\n\\n\\n\\n\\n\\n      9. Use prebuilts\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd tools¶\\nTo handle queries you chatbot can\\'t answer \"from memory\", integrate a web search tool. The chatbot can use this tool to find relevant information and provide better responses.\\n\\nNote\\nThis tutorial builds on Build a basic chatbot.\\n\\nPrerequisites¶\\nBefore you start this tutorial, ensure you have the following:\\n\\nAn API key for the Tavily Search Engine.\\n\\n1. Install the search engine¶\\nInstall the requirements to use the Tavily Search Engine:\\npip install -U langchain-tavily\\n\\n2. Configure your environment¶\\nConfigure your environment with your search engine API key:\\n_set_env(\"TAVILY_API_KEY\")\\n\\nTAVILY_API_KEY:  ········\\n\\n3. Define the tool¶\\nDefine the web search tool:\\nAPI Reference: TavilySearch\\nfrom langchain_tavily import TavilySearch\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\ntool.invoke(\"What\\'s a \\'node\\' in LangGraph?\")\\n\\nThe results are page summaries our chat bot can use to answer questions:\\n{\\'query\\': \"What\\'s a \\'node\\' in LangGraph?\",\\n\\'follow_up_questions\\': None,\\n\\'answer\\': None,\\n\\'images\\': [],\\n\\'results\\': [{\\'title\\': \"Introduction to LangGraph: A Beginner\\'s Guide - Medium\",\\n\\'url\\': \\'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\\',\\n\\'content\\': \\'Stateful Graph: LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. We define nodes for classifying the input, handling greetings, and handling search queries. def classify_input_node(state): LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph.\\',\\n\\'score\\': 0.7065353,\\n\\'raw_content\\': None},\\n{\\'title\\': \\'LangGraph Tutorial: What Is LangGraph and How to Use It?\\',\\n\\'url\\': \\'https://www.datacamp.com/tutorial/langgraph-tutorial\\',\\n\\'content\\': \\'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\\',\\n\\'score\\': 0.5008063,\\n\\'raw_content\\': None}],\\n\\'response_time\\': 1.38}\\n\\n4. Define the graph¶\\nFor the StateGraph you created in the first tutorial, add bind_tools on the LLM. This lets the LLM know the correct JSON format to use if it wants to use the search engine.\\nLet\\'s first select our LLM:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nWe can now incorporate it into a StateGraph:\\nfrom typing import Annotated\\n\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n# Modification: tell the LLM which tools it can call\\n# highlight-next-line\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\n5. Create a function to run the tools¶\\nNow, create a function to run the tools if they are called. Do this by adding the tools to a new node calledBasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM\\'s tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\\nAPI Reference: ToolMessage\\nimport json\\n\\nfrom langchain_core.messages import ToolMessage\\n\\n\\nclass BasicToolNode:\\n    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\\n\\n    def __init__(self, tools: list) -> None:\\n        self.tools_by_name = {tool.name: tool for tool in tools}\\n\\n    def __call__(self, inputs: dict):\\n        if messages := inputs.get(\"messages\", []):\\n            message = messages[-1]\\n        else:\\n            raise ValueError(\"No message found in input\")\\n        outputs = []\\n        for tool_call in message.tool_calls:\\n            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\\n                tool_call[\"args\"]\\n            )\\n            outputs.append(\\n                ToolMessage(\\n                    content=json.dumps(tool_result),\\n                    name=tool_call[\"name\"],\\n                    tool_call_id=tool_call[\"id\"],\\n                )\\n            )\\n        return {\"messages\": outputs}\\n\\n\\ntool_node = BasicToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\n\\nNote\\nIf you do not want to build this yourself in the future, you can use LangGraph\\'s prebuilt ToolNode.\\n\\n6. Define the conditional_edges¶\\nWith the tool node added, now you can define the conditional_edges. \\nEdges route the control flow from one node to the next. Conditional edges start from a single node and usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\\nNext, define a router function called route_tools that checks for tool_calls in the chatbot\\'s output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next. \\nThe condition will route to tools if tool calls are present and END if not. Because the condition can return END, you do not need to explicitly set a finish_point this time.\\ndef route_tools(\\n    state: State,\\n):\\n    \"\"\"\\n    Use in the conditional_edge to route to the ToolNode if the last message\\n    has tool calls. Otherwise, route to the end.\\n    \"\"\"\\n    if isinstance(state, list):\\n        ai_message = state[-1]\\n    elif messages := state.get(\"messages\", []):\\n        ai_message = messages[-1]\\n    else:\\n        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\\n    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\\n        return \"tools\"\\n    return END\\n\\n\\n# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\\n# it is fine directly responding. This conditional routing defines the main agent loop.\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    route_tools,\\n    # The following dictionary lets you tell the graph to interpret the condition\\'s outputs as a specific node\\n    # It defaults to the identity function, but if you\\n    # want to use a node named something else apart from \"tools\",\\n    # You can update the value of the dictionary to something else\\n    # e.g., \"tools\": \"my_tools\"\\n    {\"tools\": \"tools\", END: END},\\n)\\n# Any time a tool is called, we return to the chatbot to decide the next step\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\n\\nNote\\nYou can replace this with the prebuilt tools_condition to be more concise. \\n\\n7. Visualize the graph (optional)¶\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n8. Ask the bot questions¶\\nNow you can ask the chatbot questions outside its training data:\\ndef stream_graph_updates(user_input: str):\\n    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n        for value in event.values():\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\n\\nwhile True:\\n    try:\\n        user_input = input(\"User: \")\\n        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n            print(\"Goodbye!\")\\n            break\\n\\n        stream_graph_updates(user_input)\\n    except:\\n        # fallback if input() is not available\\n        user_input = \"What do you know about LangGraph?\"\\n        print(\"User: \" + user_input)\\n        stream_graph_updates(user_input)\\n        break\\n\\nAssistant: [{\\'text\\': \"To provide you with accurate and up-to-date information about LangGraph, I\\'ll need to search for the latest details. Let me do that for you.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01Q588CszHaSvvP2MxRq9zRD\\', \\'input\\': {\\'query\\': \\'LangGraph AI tool information\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\nAssistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\\\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\\nAssistant: Based on the search results, I can provide you with information about LangGraph:\\n\\n1. Purpose:\\n   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\n\\n2. Developer:\\n   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n\\n3. Key Features:\\n   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\\n   - Controllability: It offers enhanced control over the application flow.\\n   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\\n\\n4. Use Cases:\\n   LangGraph can be used for various applications, including:\\n   - Conversational agents\\n   - Complex task automation\\n   - Custom LLM-backed experiences\\n\\n5. Integration:\\n   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\\n\\n6. Significance:\\n...\\n   LangGraph is noted to offer unique benefits compared to other LLM frameworks, particularly in its ability to handle cycles, provide controllability, and maintain persistence.\\n\\nLangGraph appears to be a significant tool in the evolving landscape of LLM-based application development, offering developers new ways to create more complex, stateful, and interactive AI systems.\\nGoodbye!\\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\\n\\n9. Use prebuilts¶\\nFor ease of use, adjust your code to replace the following with LangGraph prebuilt components. These have built in functionality like parallel API execution.\\n\\nBasicToolNode is replaced with the prebuilt ToolNode\\nroute_tools is replaced with the prebuilt tools_condition\\n\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.messages import BaseMessage\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\n# Any time a tool is called, we return to the chatbot to decide the next step\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\ngraph = graph_builder.compile()\\n\\nCongratulations! You\\'ve created a conversational agent in LangGraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this LangSmith trace.\\nNext steps¶\\nThe chatbot cannot remember past interactions on its own, which limits its ability to have coherent, multi-turn conversations. In the next part, you will add memory to address this.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Build a basic chatbot\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add memory\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/3-add-memory/', 'title': 'Add memory', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd memory\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Add memory\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Create a MemorySaver checkpointer\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Interact with your chatbot\\n    \\n\\n\\n\\n\\n\\n      4. Ask a follow up question\\n    \\n\\n\\n\\n\\n\\n      5. Inspect the state\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Create a MemorySaver checkpointer\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Interact with your chatbot\\n    \\n\\n\\n\\n\\n\\n      4. Ask a follow up question\\n    \\n\\n\\n\\n\\n\\n      5. Inspect the state\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd memory¶\\nThe chatbot can now use tools to answer user questions, but it does not remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\\nLangGraph solves this problem through persistent checkpointing. If you provide a checkpointer when compiling the graph and a thread_id when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same thread_id, the graph loads its saved state, allowing the chatbot to pick up where it left off. \\nWe will see later that checkpointing is much more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But first, let\\'s add checkpointing to enable multi-turn conversations.\\n\\nNote\\nThis tutorial builds on Add tools.\\n\\n1. Create a MemorySaver checkpointer¶\\nCreate a MemorySaver checkpointer:\\nfrom langgraph.checkpoint.memory import MemorySaver\\n\\nmemory = MemorySaver()\\n\\nThis is in-memory checkpointer, which is convenient for the tutorial. However, in a production application, you would likely change this to use SqliteSaver or PostgresSaver and connect a database.\\n2. Compile the graph¶\\nCompile the graph with the provided checkpointer, which will checkpoint the State as the graph works through each node:\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n3. Interact with your chatbot¶\\nNow you can interact with your bot!\\n\\n\\nPick a thread to use as the key for this conversation.\\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\\n\\n\\n\\nCall your chatbot:\\nuser_input = \"Hi there! My name is Will.\"\\n\\n# The config is the **second positional argument** to stream() or invoke()!\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    config,\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nHi there! My name is Will.\\n================================== Ai Message ==================================\\n\\nHello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\\n\\n\\nNote\\nThe config was provided as the second positional argument when calling our graph. It importantly is not nested within the graph inputs ({\\'messages\\': []}).\\n\\n\\n\\n4. Ask a follow up question¶\\nAsk a follow up question:\\nuser_input = \"Remember my name?\"\\n\\n# The config is the **second positional argument** to stream() or invoke()!\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    config,\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nRemember my name?\\n================================== Ai Message ==================================\\n\\nOf course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\\n\\nNotice that we aren\\'t using an external list for memory: it\\'s all handled by the checkpointer! You can inspect the full execution in this LangSmith trace to see what\\'s going on.\\nDon\\'t believe me? Try this using a different config.\\n# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    {\"configurable\": {\"thread_id\": \"2\"}},\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nRemember my name?\\n================================== Ai Message ==================================\\n\\nI apologize, but I don\\'t have any previous context or memory of your name. As an AI assistant, I don\\'t retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?\\n\\nNotice that the only change we\\'ve made is to modify the thread_id in the config. See this call\\'s LangSmith trace for comparison.\\n5. Inspect the state¶\\nBy now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph\\'s state for a given config at any time, call get_state(config).\\nsnapshot = graph.get_state(config)\\nsnapshot\\n\\nStateSnapshot(values={\\'messages\\': [HumanMessage(content=\\'Hi there! My name is Will.\\', additional_kwargs={}, response_metadata={}, id=\\'8c1ca919-c553-4ebf-95d4-b59a2d61e078\\'), AIMessage(content=\"Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01WTQebPhNwmMrmmWojJ9KXJ\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 405, \\'output_tokens\\': 32}}, id=\\'run-58587b77-8c82-41e6-8a90-d62c444a261d-0\\', usage_metadata={\\'input_tokens\\': 405, \\'output_tokens\\': 32, \\'total_tokens\\': 437}), HumanMessage(content=\\'Remember my name?\\', additional_kwargs={}, response_metadata={}, id=\\'daba7df6-ad75-4d6b-8057-745881cea1ca\\'), AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}, next=(), config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-93e0-6acc-8004-f2ac846575d2\\'}}, metadata={\\'source\\': \\'loop\\', \\'writes\\': {\\'chatbot\\': {\\'messages\\': [AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}}, \\'step\\': 4, \\'parents\\': {}}, created_at=\\'2024-09-27T19:30:10.820758+00:00\\', parent_config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-859f-6206-8003-e1bd3c264b8f\\'}}, tasks=())\\n\\nsnapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)\\n\\nThe snapshot above contains the current state values, corresponding config, and the next node to process. In our case, the graph has reached an END state, so next is empty.\\nCongratulations! Your chatbot can now maintain conversation state across sessions thanks to LangGraph\\'s checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph\\'s checkpointing even handles arbitrarily complex graph states, which is much more expressive and powerful than simple chat memory.\\nCheck out the code snippet below to review the graph from this tutorial:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nAPI Reference: init_chat_model | TavilySearch | BaseMessage | MemorySaver | StateGraph | add_messages | ToolNode | tools_condition\\nfrom typing import Annotated\\n\\nfrom langchain.chat_models import init_chat_model\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.messages import BaseMessage\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=[tool])\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.set_entry_point(\"chatbot\")\\nmemory = MemorySaver()\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\nNext steps¶\\nIn the next tutorial, you will add human-in-the-loop to the chatbot to handle situations where it may need guidance or verification before proceeding.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Add tools\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Add human-in-the-loop\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/', 'title': 'Add human-in-the-loop', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd human-in-the-loop\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\nWe are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Add human-in-the-loop\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n            Get started\\n          \\n\\n\\n\\n\\n    Quickstart\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    LangGraph basics\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph basics\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Build a basic chatbot\\n    \\n  \\n\\n\\n\\n\\n\\n    Add tools\\n    \\n  \\n\\n\\n\\n\\n\\n    Add memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n    Add human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Add the human_assistance tool\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      4. Prompt the chatbot\\n    \\n\\n\\n\\n\\n\\n      5. Resume execution\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Customize state\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Prebuilt agents\\n    \\n  \\n\\n\\n\\n\\n\\n            Prebuilt agents\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Running agents\\n    \\n  \\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP Integration\\n    \\n  \\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n    Evals\\n    \\n  \\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n    UI\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph framework\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph framework\\n          \\n\\n\\n\\n\\n    Agent architectures\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Graphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph Platform\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Components\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Threads\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n    Breakpoints\\n    \\n  \\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      1. Add the human_assistance tool\\n    \\n\\n\\n\\n\\n\\n      2. Compile the graph\\n    \\n\\n\\n\\n\\n\\n      3. Visualize the graph (optional)\\n    \\n\\n\\n\\n\\n\\n      4. Prompt the chatbot\\n    \\n\\n\\n\\n\\n\\n      5. Resume execution\\n    \\n\\n\\n\\n\\n\\n      Next steps\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd human-in-the-loop controls¶\\nAgents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\\nLangGraph\\'s persistence layer supports human-in-the-loop workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the interrupt function. Calling interrupt inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a Command. interrupt is ergonomically similar to Python\\'s built-in input(), with some caveats.\\n\\nNote\\nThis tutorial builds on Add memory.\\n\\n1. Add the human_assistance tool¶\\nStarting with the existing code from the Add memory to the chatbot tutorial, add the human_assistance tool to the chatbot. This tool uses interrupt to receive information from a human.\\nLet\\'s first select a chat model:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\n\\nWe can now incorporate it into our StateGraph with an additional tool:\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.tools import tool\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\n\\nfrom langgraph.types import Command, interrupt\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool, human_assistance]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    message = llm_with_tools.invoke(state[\"messages\"])\\n    # Because we will be interrupting during tool execution,\\n    # we disable parallel tool calling to avoid repeating any\\n    # tool invocations when we resume.\\n    assert len(message.tool_calls) <= 1\\n    return {\"messages\": [message]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=tools)\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\n\\nTip\\nFor more information and examples of human-in-the-loop workflows, see Human-in-the-loop. This includes how to review and edit tool calls before they are executed.\\n\\n2. Compile the graph¶\\nWe compile the graph with a checkpointer, as before:\\nmemory = MemorySaver()\\n\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\n3. Visualize the graph (optional)¶\\nVisualizing the graph, you get the same layout as before – just with the added tool!\\nfrom IPython.display import Image, display\\n\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    # This requires some extra dependencies and is optional\\n    pass\\n\\n\\n4. Prompt the chatbot¶\\nNow, prompt the chatbot with a question that will engage the new human_assistance tool:\\nuser_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\\nconfig = {\"configurable\": {\"thread_id\": \"1\"}}\\n\\nevents = graph.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n    config,\\n    stream_mode=\"values\",\\n)\\nfor event in events:\\n    if \"messages\" in event:\\n        event[\"messages\"][-1].pretty_print()\\n\\n================================ Human Message =================================\\n\\nI need some expert guidance for building an AI agent. Could you request assistance for me?\\n================================== Ai Message ==================================\\n\\n[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\nTool Calls:\\n  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n  Args:\\n    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n\\nThe chatbot generated a tool call, but then execution has been interrupted. If you inspect the graph state, you see that it stopped at the tools node:\\nsnapshot = graph.get_state(config)\\nsnapshot.next\\n\\n(\\'tools\\',)\\n\\n\\nInfo\\nTake a closer look at the human_assistance tool:\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\nSimilar to Python\\'s built-in input() function, calling interrupt inside the tool will pause execution. Progress is persisted based on the checkpointer; so if it is persisting with Postgres, it can resume at any time as long as the database is alive. In this example, it is persisting with the in-memory checkpointer and can resume any time if the Python kernel is running.\\n\\n5. Resume execution¶\\nTo resume execution, pass a Command object containing data expected by the tool. The format of this data can be customized based on needs. For this example, use a dict with a key \"data\":\\nhuman_response = (\\n    \"We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent.\"\\n    \" It\\'s much more reliable and extensible than simple autonomous agents.\"\\n)\\n\\nhuman_command = Command(resume={\"data\": human_response})\\n\\nevents = graph.stream(human_command, config, stream_mode=\"values\")\\nfor event in events:\\n    if \"messages\" in event:\\n        event[\"messages\"][-1].pretty_print()\\n\\n================================== Ai Message ==================================\\n\\n[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\nTool Calls:\\n  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n  Args:\\n    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n================================= Tool Message =================================\\nName: human_assistance\\n\\nWe, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent. It\\'s much more reliable and extensible than simple autonomous agents.\\n================================== Ai Message ==================================\\n\\nThank you for your patience. I\\'ve received some expert advice regarding your request for guidance on building an AI agent. Here\\'s what the experts have suggested:\\n\\nThe experts recommend that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\\n\\nLangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n\\n1. Reliability: The experts emphasize that LangGraph is more reliable than simpler autonomous agent approaches. This could mean it has better stability, error handling, or consistent performance.\\n\\n2. Extensibility: LangGraph is described as more extensible, which suggests that it probably offers a flexible architecture that allows you to easily add new features or modify existing ones as your agent\\'s requirements evolve.\\n\\n3. Advanced capabilities: Given that it\\'s recommended over \"simple autonomous agents,\" LangGraph likely provides more sophisticated tools and techniques for building complex AI agents.\\n...\\n2. Look for tutorials or guides specifically focused on building AI agents with LangGraph.\\n3. Check if there are any community forums or discussion groups where you can ask questions and get support from other developers using LangGraph.\\n\\nIf you\\'d like more specific information about LangGraph or have any questions about this recommendation, please feel free to ask, and I can request further assistance from the experts.\\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\\n\\nThe input has been received and processed as a tool message. Review this call\\'s LangSmith trace to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\\nCongratulations! You\\'ve used an interrupt to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since you have already added a checkpointer, as long as the underlying persistence layer is running, the graph can be paused indefinitely and resumed at any time as if nothing had happened.\\nCheck out the code snippet below to review the graph from this tutorial:\\nOpenAIAnthropicAzureGoogle GeminiAWS Bedrock\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"openai:gpt-4.1\")\\n\\n\\n\\npip install -U \"langchain[anthropic]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-...\"\\n\\nllm = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\\n\\n\\n\\npip install -U \"langchain[openai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\\nos.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"...\"\\nos.environ[\"OPENAI_API_VERSION\"] = \"2025-03-01-preview\"\\n\\nllm = init_chat_model(\\n    \"azure_openai:gpt-4.1\",\\n    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\\n)\\n\\n\\n\\npip install -U \"langchain[google-genai]\"\\n\\nimport os\\nfrom langchain.chat_models import init_chat_model\\n\\nos.environ[\"GOOGLE_API_KEY\"] = \"...\"\\n\\nllm = init_chat_model(\"google_genai:gemini-2.0-flash\")\\n\\n\\n\\npip install -U \"langchain[aws]\"\\n\\nfrom langchain.chat_models import init_chat_model\\n\\n# Follow the steps here to configure your credentials:\\n# https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html\\n\\nllm = init_chat_model(\\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\\n    model_provider=\"bedrock_converse\",\\n)\\n\\n\\n\\n\\nAPI Reference: TavilySearch | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nfrom typing import Annotated\\n\\nfrom langchain_tavily import TavilySearch\\nfrom langchain_core.tools import tool\\nfrom typing_extensions import TypedDict\\n\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langgraph.graph import StateGraph, START, END\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.prebuilt import ToolNode, tools_condition\\nfrom langgraph.types import Command, interrupt\\n\\nclass State(TypedDict):\\n    messages: Annotated[list, add_messages]\\n\\ngraph_builder = StateGraph(State)\\n\\n@tool\\ndef human_assistance(query: str) -> str:\\n    \"\"\"Request assistance from a human.\"\"\"\\n    human_response = interrupt({\"query\": query})\\n    return human_response[\"data\"]\\n\\ntool = TavilySearch(max_results=2)\\ntools = [tool, human_assistance]\\nllm_with_tools = llm.bind_tools(tools)\\n\\ndef chatbot(state: State):\\n    message = llm_with_tools.invoke(state[\"messages\"])\\n    assert(len(message.tool_calls) <= 1)\\n    return {\"messages\": [message]}\\n\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n\\ntool_node = ToolNode(tools=tools)\\ngraph_builder.add_node(\"tools\", tool_node)\\n\\ngraph_builder.add_conditional_edges(\\n    \"chatbot\",\\n    tools_condition,\\n)\\ngraph_builder.add_edge(\"tools\", \"chatbot\")\\ngraph_builder.add_edge(START, \"chatbot\")\\n\\nmemory = MemorySaver()\\ngraph = graph_builder.compile(checkpointer=memory)\\n\\nNext steps¶\\nSo far, the tutorial examples have relied on a simple state with one entry: a list of messages. You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state.\\n\\n\\n\\n        Was this page helpful?\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback!\\n            \\n\\n              \\n              \\n                \\n              \\n              \\n              \\n                \\n                \\n              \\n              Thanks for your feedback! Please help us improve this page by adding to the discussion below.\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Add memory\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Customize state\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\n\\n\\n\\n\\n\\n\\n      Google Analytics\\n    \\n\\n\\n\\n\\n\\n      GitHub\\n    \\n\\n\\n\\n\\nAccept\\nReject\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "doc_split = text_splitter.split_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Build a basic chatbot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Skip to content\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.  Join our team!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            LangGraph\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "              Build a basic chatbot\n",
      "            \n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Initializing search\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    GitHub\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "  \n",
      "    \n",
      "  \n",
      "  Guides\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "  \n",
      "    \n",
      "  \n",
      "  Reference\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "  \n",
      "    \n",
      "  \n",
      "  Examples\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "  \n",
      "  \n",
      "    \n",
      "  \n",
      "  Resources\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    LangGraph\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    GitHub\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Guides\n",
      "    \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Guides\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Get started\n",
      "    \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Get started\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Quickstart\n",
      "    \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    LangGraph basics\n",
      "    \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            LangGraph basics\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Overview\n",
      "    \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Build a basic chatbot' metadata={'source': 'https://langchain-ai.github.io/langgraph/tutorials/get-started/1-build-basic-chatbot/#2-create-a-stategraph', 'title': 'Build a basic chatbot', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(doc_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=doc_split,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_vector_db_blog\",\n",
    "    \"search and run information about langgraph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='retriever_vector_db_blog', description='search and run information about langgraph', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x10b6bd750>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x10fceeec0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x10b6bd6c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x10fceeec0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets create the same for some other set of documents\n",
    "\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/introduction/?_gl=1*i5birr*_gcl_au*Njc3NjI4MDIyLjE3NDkyMjkyNDA.*_ga*MjI4MDY2MjM1LjE3NDkyMjkzNTk.*_ga_47WX3HKKY2*czE3NDkzOTcyODAkbzIkZzAkdDE3NDkzOTcyODgkajUyJGwwJGgw\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/2-add-tools/#1-install-the-search-engine\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/3-add-memory/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/tutorials/get-started/4-human-in-the-loop/\"\n",
    "]\n",
    "\n",
    "documents = [WebBaseLoader(url).load() for url in urls]\n",
    "doc_list = [items for sublist in documents for items in sublist]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "doc_split = text_splitter.split_documents(doc_list)\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=doc_split,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever_langchain = vectorstore.as_retriever()\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool_lanchain= create_retriever_tool(\n",
    "    retriever_langchain,\n",
    "    \"retriever_vector_db_blog_langchain\",\n",
    "    \"search and run information about langchain\"\n",
    ")\n",
    "#documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, retriever_tool_lanchain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangGraph Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages : Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 11, 'total_tokens': 36, 'completion_time': 0.071428571, 'prompt_time': 0.000120508, 'queue_time': 0.049514388, 'total_time': 0.071549079}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None}, id='run--aa5f9012-c478-4e7a-a7bd-6e565324bd5e-0', usage_metadata={'input_tokens': 11, 'output_tokens': 25, 'total_tokens': 36})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    print(\"--CALL Agent--\")\n",
    "    messages = state['messages']\n",
    "    model = ChatGroq(model='llama3-70b-8192')\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\" : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def grade_documents(state) ->Literal['generate', 'rewrite']:\n",
    "    ## It determines wheather the retrieved document is relavent or not.\n",
    "    print(\"--Checking relavance--\")\n",
    "\n",
    "    ##Data Model\n",
    "    class grade(BaseModel):\n",
    "        binary_score:str = Field(description=\"relavance score 'yes\" or 'no')\n",
    "\n",
    "    model = ChatGroq(model='llama3-70b-8192')\n",
    "\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relavance of a retreived document to a user question. \\n\n",
    "        Here is the retrieved document: \\n\\n{context}\\n\\n\n",
    "        Here is the user question: \\n\\n{question}\\n\\n\n",
    "        If the docuemt containes the keywords or semantic meaning related to the user question, grade it as relavent.\\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate wheather the document is relavent or not\"\"\",\n",
    "        input_variables=['context', 'question'],\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages= state['messages']\n",
    "    last_message = messages[-1]\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "    scored_result = chain.invoke({'question': question, 'context': docs})\n",
    "    score = scored_result.binary_score\n",
    "    if score =='yes':\n",
    "        print(\"--Decision : Docs Relavant\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"--Decision : Docs not relavent--\")\n",
    "        print(score)\n",
    "        return 'rewrite'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    print(\"--generate--\")\n",
    "    messages = state['messages']\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "    docs = last_message.content\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    llm = ChatGroq(model=\"llama3-70b-8192\")\n",
    "    ## postprocessing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    ## Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\":[response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    ## transform the query to produce better question\n",
    "    print(\"--Tranform Query--\")\n",
    "    messages = state['messages']\n",
    "    question = messages[0].content\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"\\n\n",
    "        Look at the input and try to reason about the underlying semantic intent  / meaning. \\n\n",
    "        Here is the initial question :\n",
    "        \\n ....... \\n\n",
    "        {question}\n",
    "        \\n ........ \\n \n",
    "        Formulate the improved question:\"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    ## Grader\n",
    "    model = ChatGroq(model='llama3-70b-8192')\n",
    "    response = model.invoke(msg)\n",
    "    return {\"message\" : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n",
    "## Define a new Graph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "retrieve = ToolNode([retriever_tool, retriever_tool_lanchain])\n",
    "\n",
    "workflow.add_node('retrieve', retrieve)\n",
    "workflow.add_node('rewrite', rewrite)\n",
    "workflow.add_node('generate', generate)\n",
    "\n",
    "workflow.add_edge(START, 'agent')\n",
    "## Decide wheather to retrive or rewrite\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        'tools' : 'retrieve',\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "## edges taken after the actio node\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    ## Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge('rewrite', 'agent')\n",
    "## Compile\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--CALL Agent--\n",
      "--Checking relavance--\n",
      "--Decision : Docs Relavant\n",
      "--generate--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is langgraph', additional_kwargs={}, response_metadata={}, id='9c2cbc8e-c857-475d-b224-fa62d4e420a5'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_x8ce', 'function': {'arguments': '{\"query\":\"langgraph\"}', 'name': 'retriever_vector_db_blog'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1013, 'total_tokens': 1061, 'completion_time': 0.154675046, 'prompt_time': 0.033245261, 'queue_time': 0.051796309, 'total_time': 0.187920307}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e8ed4c60-3bcc-4b40-ad87-bfeca78271ab-0', tool_calls=[{'name': 'retriever_vector_db_blog', 'args': {'query': 'langgraph'}, 'id': 'call_x8ce', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1013, 'output_tokens': 48, 'total_tokens': 1061}),\n",
       "  ToolMessage(content='Assistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\\\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\\nAssistant: Based on the search results, I can provide you with information about LangGraph:\\n\\n2. Extensibility: LangGraph is described as more extensible, which suggests that it probably offers a flexible architecture that allows you to easily add new features or modify existing ones as your agent\\'s requirements evolve.\\n\\n3. Advanced capabilities: Given that it\\'s recommended over \"simple autonomous agents,\" LangGraph likely provides more sophisticated tools and techniques for building complex AI agents.\\n...\\n2. Look for tutorials or guides specifically focused on building AI agents with LangGraph.\\n3. Check if there are any community forums or discussion groups where you can ask questions and get support from other developers using LangGraph.\\n\\nIf you\\'d like more specific information about LangGraph or have any questions about this recommendation, please feel free to ask, and I can request further assistance from the experts.\\nOutput is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\\n\\n\\'url\\': \\'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\\',\\n\\'content\\': \\'Stateful Graph: LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. We define nodes for classifying the input, handling greetings, and handling search queries. def classify_input_node(state): LangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph.\\',\\n\\'score\\': 0.7065353,\\n\\'raw_content\\': None},\\n\\n1. Purpose:\\n   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\n\\n2. Developer:\\n   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n\\n3. Key Features:\\n   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\\n   - Controllability: It offers enhanced control over the application flow.\\n   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\\n\\n4. Use Cases:\\n   LangGraph can be used for various applications, including:\\n   - Conversational agents\\n   - Complex task automation\\n   - Custom LLM-backed experiences', name='retriever_vector_db_blog', id='e726ec85-2abf-41da-9b46-901180e6ae9e', tool_call_id='call_x8ce'),\n",
       "  HumanMessage(content='LangGraph is a library for building stateful, multi-actor applications with Large Language Models (LLMs), particularly useful for creating agent and multi-agent workflows. It sets the foundation for building and scaling AI workloads from conversational agents to custom LLM-backed experiences.', additional_kwargs={}, response_metadata={}, id='bed5f5c5-fcde-49e0-94d5-4f04503130cc')]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": \"what is langgraph\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--CALL Agent--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who is Balmukund', additional_kwargs={}, response_metadata={}, id='df6faa72-09fe-4ed4-b4b3-7fa464a35165'),\n",
       "  AIMessage(content='Balmukund Singh is an Indian fitness trainer, YouTuber, and entrepreneur. He is known for his fitness journey, where he transformed his body from being overweight to fit and healthy.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 2051, 'total_tokens': 2091, 'completion_time': 0.244573615, 'prompt_time': 0.07554713, 'queue_time': -0.23547752, 'total_time': 0.320120745}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None}, id='run--c87e7ca0-46ff-4cae-8ae2-994093ffbfbf-0', usage_metadata={'input_tokens': 2051, 'output_tokens': 40, 'total_tokens': 2091})]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": \"who is Balmukund\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
